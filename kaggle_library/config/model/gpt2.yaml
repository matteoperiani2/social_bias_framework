name: gpt2
checkpoint_name: gpt2
batch_size: 8
num_epochs: 1 
learning_rate: 1e-5
padding_side: left
warmup_fraction: 0.2
checkpoint_interval: 700
log_interval: 1000
eval_interval: 1000

checkpoint_dir: checkpoints/gpt2

data:
  train: data/gpt2/train
  evaluation: data/gpt2/evaluation

special_tokens:
  pad_token: <|pad|>
  sep_token: <|sep|>
  additional_special_tokens:
    - <|offY|>
    - <|offN|>
    - <|sexY|>
    - <|sexN|>
    - <|intY|>
    - <|intN|>
    - <|grpY|>
    - <|grpN|>
    - <|ingrpY|>
    - <|ingrpN|>

cls_token_map:
  - 0: <|offN|>
    1: <|offY|>
  - 0: <|intN|>
    1: <|intY|>
  - 0: <|sexN|>
    1: <|sexY|>
  - 0: <|grpN|>
    1: <|grpY|>
  - 0: <|ingrpN|>
    1: <|ingrpY|>


classification_pos_freq:
  offY:  0.579
  intY: 0.516
  sexY: 0.091
  grpY: 0.644
  ingrpY: 0.087


generation_params:
  gen_cfg.max_new_tokens: 100
  gen_cfg.do_sample: False
  gen_cfg.num_beams: 1

# ce_wights:
#   50259: 0.2
#   50260: 0.3
#   50261: 0.5
#   50262: 0.4
#   50263:
#   50264:
#   50265:
#   50266:
#   50267:
#   50268: