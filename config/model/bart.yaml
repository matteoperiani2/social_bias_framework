name: bart
checkpoint_name: facebook/bart-base
batch_size: 8
learning_rate: 1e-5
padding_side: right
decoder_max_length: 512
warmup_fraction: 0.1
checkpoint_interval: 700
log_interval: 700
eval_interval: 700

data:
  processed: data/preproc
  aggregated: data/aggregated
  train: data/train
  prediction: data/predictions

generation_parameters:
  penalty_alpha: 0.4
  top_k: 4