name: gpt2
checkpoint_name: gpt2
batch_size: 4
val_batch_size: 16
num_epochs: 1 
learning_rate: 1e-5
padding_side: left
warmup_fraction: 0.2
checkpoint_dir: checkpoints/gpt2
accumulation_steps: 1
generate_batch_size: 16

special_tokens:
  pad_token: <|pad|>
  sep_token: <|sep|>
  additional_special_tokens:
    - <|offY|>
    - <|offN|>
    - <|sexY|>
    - <|sexN|>
    - <|intY|>
    - <|intN|>
    - <|grpY|>
    - <|grpN|>
    - <|ingrpY|>
    - <|ingrpN|>


cls_token_map:
  - 0: <|offN|>
    1: <|offY|>
  - 0: <|intN|>
    1: <|intY|>
  - 0: <|sexN|>
    1: <|sexY|>
  - 0: <|grpN|>
    1: <|grpY|>
  - 0: <|ingrpN|>
    1: <|ingrpY|>


classification_pos_freq:
  'off': 0.485
  int: 0.515
  sex: 0.085
  vs_group: 0.656
  in_group: 0.023


generation_params:
  max_new_tokens: 100
  do_sample: False
  num_beams: 1