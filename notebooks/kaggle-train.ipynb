{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-23T04:35:18.019868Z","iopub.status.busy":"2023-12-23T04:35:18.019559Z","iopub.status.idle":"2023-12-23T04:35:18.029680Z","shell.execute_reply":"2023-12-23T04:35:18.028665Z","shell.execute_reply.started":"2023-12-23T04:35:18.019841Z"},"trusted":true},"outputs":[],"source":["import sys\n","sys.path.append('/kaggle/input/kaggle-lib/kaggle_lib')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-23T04:35:18.030994Z","iopub.status.busy":"2023-12-23T04:35:18.030721Z","iopub.status.idle":"2023-12-23T04:35:30.309618Z","shell.execute_reply":"2023-12-23T04:35:30.308397Z","shell.execute_reply.started":"2023-12-23T04:35:18.030965Z"},"trusted":true},"outputs":[],"source":["%pip install omegaconf angle-emb emoji"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-23T04:35:30.311574Z","iopub.status.busy":"2023-12-23T04:35:30.311172Z","iopub.status.idle":"2023-12-23T04:35:40.291565Z","shell.execute_reply":"2023-12-23T04:35:40.290494Z","shell.execute_reply.started":"2023-12-23T04:35:30.311515Z"},"trusted":true},"outputs":[],"source":["import gc, os, torch, wandb, pandas\n","from datasets import Dataset\n","from src.config import Config\n","from src.models import model_helper_factory\n","from src.train_utils import fix_reproducibility, train\n","from src.logging import WandbLogger\n","from kaggle_secrets import UserSecretsClient\n","\n","user_secrets = UserSecretsClient()\n","wandb_api_key = user_secrets.get_secret(\"wandb-api-key\")\n","\n","os.environ[\"WANDB_API_KEY\"] = wandb_api_key\n","wandb.login()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-23T04:35:40.294324Z","iopub.status.busy":"2023-12-23T04:35:40.293673Z","iopub.status.idle":"2023-12-23T04:35:40.331369Z","shell.execute_reply":"2023-12-23T04:35:40.330458Z","shell.execute_reply.started":"2023-12-23T04:35:40.294295Z"},"trusted":true},"outputs":[],"source":["model_name = \"bart\"\n","\n","config = Config.load_config(\n","    config_path=\"/kaggle/input/kaggle-lib/kaggle_lib/config\", model_name=model_name\n",")\n","config = Config.to_dict(config)\n","config[\"seed\"] = 42"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-23T04:35:40.333251Z","iopub.status.busy":"2023-12-23T04:35:40.332602Z","iopub.status.idle":"2023-12-23T04:36:39.062594Z","shell.execute_reply":"2023-12-23T04:36:39.060983Z","shell.execute_reply.started":"2023-12-23T04:35:40.333215Z"},"trusted":true},"outputs":[],"source":["os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"true\"\n","\n","with WandbLogger().init_wandb(**config[\"wandb\"], config=config):\n","    config = wandb.config\n","    fix_reproducibility(config.seed)\n","\n","    # get the train helper\n","    train_helper = model_helper_factory(config)\n","\n","    # Make the tokenizer and the model\n","    tokenizer = train_helper.make_tokenizer()\n","    model = train_helper.make_model(tokenizer)\n","    \n","    # Make the data\n","    train_dataset = Dataset.from_pandas(pandas.read_pickle(f'/kaggle/input/{model_name}-train/train.pkl'))\n","    val_dataset =  Dataset.from_pandas(pandas.read_pickle(f'/kaggle/input/{model_name}-train/val.pkl'))\n","#     train_dataset = train_dataset.select(range(16))\n","#     val_dataset = val_dataset.select(range(60))\n","    \n","    collator = train_helper.make_data_collator(tokenizer, model)\n","\n","    train_dataloader = train_helper.make_dataloader(\n","        train_dataset, collate_fn=collator, split=\"train\"\n","    )\n","    val_dataloader = train_helper.make_dataloader(\n","        val_dataset, collate_fn=collator, split=\"val\"\n","    )\n","\n","    # Make the loss, the optimizer and the scheduler\n","    optimizer = train_helper.make_optimizer(model)\n","    scheduler = train_helper.make_scheduler(\n","        optimizer, steps_per_epoch=len(train_dataloader)\n","    )\n","\n","    loss_fn = train_helper.make_loss(tokenizer)\n","\n","    train(\n","        model,\n","        train_dataloader,\n","        val_dataloader,\n","        optimizer,\n","        loss_fn,\n","        scheduler,\n","        config,\n","    )\n","\n","gc.collect()\n","torch.cuda.empty_cache()\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4204654,"sourceId":7263307,"sourceType":"datasetVersion"},{"datasetId":4210409,"sourceId":7265989,"sourceType":"datasetVersion"},{"datasetId":4204524,"sourceId":7268629,"sourceType":"datasetVersion"}],"dockerImageVersionId":30627,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
