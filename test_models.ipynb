{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 18:30:04.135406: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-02 18:30:04.768736: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmatteo-periani\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import deque\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import set_seed\n",
    "\n",
    "from src.config import Config\n",
    "from src.dataset import SBICDataCollator, SBICDataset\n",
    "from src.utils import PropertyDict\n",
    "from src.train_utils import *\n",
    "\n",
    "CONFIG:Config = Config()\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = PropertyDict(\n",
    "    seed=42,\n",
    "    checkpoint_name=\"distilgpt2\",\n",
    "    model_name=\"distilgpt2\",\n",
    "    padding_side=\"left\",\n",
    "    batch_size=32,\n",
    "    val_batch_size=16,\n",
    "    num_workers=0,\n",
    "    num_epochs=20,\n",
    "    learning_rate=5e-4,\n",
    "    scheduler=\"linear\",\n",
    "    warmup_fraction=0.1,\n",
    "    accumulation_steps=1,\n",
    "    gradient_clip = 1.0,\n",
    "    mixed_precision=\"fp16\",\n",
    "    checkpoint_interval=1000,\n",
    "    log_interval=1000,\n",
    "    cpu=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matteo/github/social_bias_framework/wandb/run-20231002_183007-eqh3zx0q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/matteo-periani/matteo-periani/runs/eqh3zx0q' target=\"_blank\">dutiful-shape-13</a></strong> to <a href='https://wandb.ai/matteo-periani/matteo-periani' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/matteo-periani/matteo-periani' target=\"_blank\">https://wandb.ai/matteo-periani/matteo-periani</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/matteo-periani/matteo-periani/runs/eqh3zx0q' target=\"_blank\">https://wandb.ai/matteo-periani/matteo-periani/runs/eqh3zx0q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all special token and its token_id:\n",
      " - ['<|endoftext|>', '<|sep|>', '<|pad|>', '<|offY|>', '<|offN|>', '<|sexY|>', '<|sexN|>', '<|intY|>', '<|intN|>', '<|grpY|>', '<|grpN|>', '<|ingrpN|>', '<|ingrpY|>']\n",
      " - [[50256], [50258], [50257], [50259], [50260], [50261], [50262], [50263], [50264], [50265], [50266], [50267], [50268]]\n",
      "Model vocab resize: 50269\n",
      "Model eos token: 50256\n",
      "Model pad token: 50257\n",
      "Model sep token: 50258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/640 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 640/640 [02:55<00:00,  3.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>▁▃▅▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>1e-05</td></tr><tr><td>train_loss</td><td>0.09683</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dutiful-shape-13</strong> at: <a href='https://wandb.ai/matteo-periani/matteo-periani/runs/eqh3zx0q' target=\"_blank\">https://wandb.ai/matteo-periani/matteo-periani/runs/eqh3zx0q</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231002_183007-eqh3zx0q/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project=CONFIG.wandbConfig.project, config=hyperparameters):\n",
    "    config = wandb.config\n",
    "\n",
    "    set_seed(CONFIG.seed)\n",
    "\n",
    "    # Make the model\n",
    "    tokenizer = make_tokinzer(config)\n",
    "    model = make_model(config, tokenizer)\n",
    "\n",
    "    # Make the data\n",
    "    train_data = get_data(\"train\")[:1024]\n",
    "    train_dataset = SBICDataset(train_data, tokenizer)\n",
    "\n",
    "    val_data = get_data(\"validation\")[:1024]\n",
    "    val_dataset = SBICDataset(train_data, tokenizer)\n",
    "\n",
    "    train_dataloader = make_dataloader(train_dataset, model, tokenizer, config, split=\"train\")\n",
    "    val_dataloader = make_dataloader(val_dataset, model, tokenizer, config, split=\"validation\")\n",
    "\n",
    "    # Make the loss, the optimizer and the scheduler\n",
    "    optimizer = make_optimizer(model, config)\n",
    "    scheduler = make_scheduler(\n",
    "        optimizer, steps_per_epoch=len(train_dataloader), config=config\n",
    "    )\n",
    "\n",
    "    # model, train_dataloader, val_dataloader, loss_fn, optimizer, scheduler, metrics = make(config)\n",
    "    # print(model)\n",
    "\n",
    "    train(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        val_dataloader,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        config,\n",
    "    )\n",
    "\n",
    "    # results = evaluate(model, tokenizer, train_data, val_data, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input string: RT @iBeZo: Stupid fucking nigger LeBron. You flopping stupid jungle bunny monkey faggot.<|sep|>\n",
      "Forward output:  <|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|intY|><|grpN|><|intN|><|intN|><|intN|><|intN|><|intY|><|intY|><|sexN|><|grpY|><|intY|><|intY|><|intY|>as<|intY|><|intY|><|grpY|><|grpY|><|intY|><|sexN|>ots<|grpY|><|intY|>\n",
      "Generate output:  <|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|><|pad|>RT @iBeZo: Stupid fucking nigger LeBron. You flopping stupid jungle bunny monkey faggot.<|sep|><|grpY|><|intY|><|sexN|><|offY|><|sep|>black folks<|sep|>black people are monkeys<|sep|><|ingrpN|><|endoftext|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteo/miniconda3/envs/nlp/lib/python3.11/site-packages/transformers/generation/utils.py:1255: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"checkpoints/gpt2_512_16.pt\"))\n",
    "model.eval()\n",
    "model.to(CONFIG.train_params.device)\n",
    "\n",
    "input_str = train_data[3][5] + tokenizer.sep_token\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(\n",
    "        input_str, truncation=True, padding=\"max_length\", max_length=256, return_tensors=\"pt\"\n",
    "    )\n",
    "    inputs = {k: v.to(CONFIG.train_params.device) for k, v in inputs.items()}\n",
    "\n",
    "    forward_out = model(**inputs)\n",
    "    logits = forward_out.logits[0, :-1, :]\n",
    "    forward_tokens = torch.argmax(logits, axis=-1)\n",
    "\n",
    "    generate_out = model.generate(**inputs, max_new_tokens=50)\n",
    "    generate_tokens = generate_out.cpu().numpy()[0]\n",
    "    \n",
    "    print(\"Input string:\", input_str)\n",
    "    print(\"Forward output: \", tokenizer.decode(forward_tokens, skip_special_tokens=False))\n",
    "    print(\"Generate output: \", tokenizer.decode(generate_tokens, skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0, 1.0, 0.0, 1.0, 0.0,\n",
       "       'RT @iBeZo: Stupid fucking nigger LeBron. You flopping stupid jungle bunny monkey faggot.',\n",
       "       'black folks', 'race', 'all stupid', 't/davidson'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
