{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, GPT2LMHeadModel, set_seed\n",
    "\n",
    "from src.config import Config\n",
    "\n",
    "CONFIG:Config = Config()\n",
    "set_seed(CONFIG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>whoTarget</th>\n",
       "      <th>intentYN</th>\n",
       "      <th>sexYN</th>\n",
       "      <th>offensiveYN</th>\n",
       "      <th>speakerMinorityYN</th>\n",
       "      <th>post</th>\n",
       "      <th>targetMinority</th>\n",
       "      <th>targetCategory</th>\n",
       "      <th>targetStereotype</th>\n",
       "      <th>dataSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>t/davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>t/davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>t/davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>black folks</td>\n",
       "      <td>race</td>\n",
       "      <td>all stupid</td>\n",
       "      <td>t/davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>black folks</td>\n",
       "      <td>race</td>\n",
       "      <td>are not people but apes.</td>\n",
       "      <td>t/davidson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   whoTarget  intentYN  sexYN  offensiveYN  speakerMinorityYN  \\\n",
       "0        0.0       1.0    0.0          1.0                0.0   \n",
       "1        0.0       1.0    0.0          1.0                0.0   \n",
       "2        0.0       0.0    0.0          1.0                0.0   \n",
       "3        1.0       1.0    0.0          1.0                0.0   \n",
       "4        1.0       1.0    0.0          1.0                0.0   \n",
       "\n",
       "                                                post targetMinority  \\\n",
       "0  RT @_LexC__: I'm convinced that some of y'all ...                  \n",
       "1  RT @_LexC__: I'm convinced that some of y'all ...                  \n",
       "2  RT @_LexC__: I'm convinced that some of y'all ...                  \n",
       "3  RT @iBeZo: Stupid fucking nigger LeBron. You f...    black folks   \n",
       "4  RT @iBeZo: Stupid fucking nigger LeBron. You f...    black folks   \n",
       "\n",
       "  targetCategory          targetStereotype  dataSource  \n",
       "0                                           t/davidson  \n",
       "1                                           t/davidson  \n",
       "2                                           t/davidson  \n",
       "3           race                all stupid  t/davidson  \n",
       "4           race  are not people but apes.  t/davidson  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(CONFIG.dataset.train_data_raw)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label_encoder = {\n",
    "    0: {0: \"[grpN]\", 1: \"[grpY]\"},\n",
    "    1: {0: \"[intN]\", 1: \"[intY]\"},\n",
    "    2: {0: \"[sexN]\", 1: \"[sexY]\"},\n",
    "    3: {0: \"[offN]\", 1: \"[offY]\"},\n",
    "    4: {0: \"[ingrpN]\", 1: \"[ingrpY]\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[grpN][SEP][intY][SEP][sexN][SEP][offY][SEP]ciao come stai[SEP]bene tu[SEP][ingrpN]'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = df.to_numpy()[0][:5]\n",
    "t_enc = [class_label_encoder[idx][a] for idx,a in enumerate(t)]\n",
    "\"[SEP]\".join(t_enc[:4]) + \"[SEP]\" + \"ciao come stai\" + \"[SEP]\" + \"bene tu\" + \"[SEP]\" + t_enc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(text=\"ciao sono Matteo\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEP] 50258\n",
      "[PAD] 50257\n",
      "All special tokens: ['<|endoftext|>', '[SEP]', '[PAD]', '[offY]', '[offN]', '[sexY]', '[sexN]', '[intY]', '[intN]', '[grpY]', '[grpN]', '[ingrpN]', '[ingrpY]']\n",
      "All special ids: [50256, 50258, 50257, 50259, 50260, 50261, 50262, 50263, 50264, 50265, 50266, 50267, 50268]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "# encoder = AutoTokenizer.from_pretrained('gpt2')\n",
    "SPECIAL_TOKENS = {\n",
    "    'pad_token': '[PAD]',\n",
    "    'sep_token': '[SEP]',\n",
    "    \"additional_special_tokens\": [\"[offY]\", \"[offN]\", \"[sexY]\", \"[sexN]\", \"[intY]\", \n",
    "                                   \"[intN]\", \"[grpY]\", \"[grpN]\", \"[ingrpN]\", \"[ingrpY]\"]\n",
    "}\n",
    "tokenizer.add_special_tokens(SPECIAL_TOKENS)\n",
    "print(tokenizer.sep_token, tokenizer.sep_token_id)\n",
    "print(tokenizer.pad_token, tokenizer.pad_token_id)\n",
    "print('All special tokens:', tokenizer.all_special_tokens)\n",
    "print('All special ids:', tokenizer.all_special_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [66, 13481, 3367, 78, 8966, 78, 6362, 12777, 50257, 50257, 50257, 50257, 50257, 50257, 50257], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]}\n",
      "ciao sono belloanche tu[PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n"
     ]
    }
   ],
   "source": [
    "a = tokenizer(\"ciao sono bello\", \"anche tu\", max_length=15, padding=\"max_length\", add_special_tokens=True)\n",
    "print(a)\n",
    "print(tokenizer.decode(a[\"input_ids\"], skip_special_tokens=False))\n",
    "model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenize_function' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/matteo/github/social_bias_framework/test_models.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/matteo/github/social_bias_framework/test_models.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m dataset_train \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mfrom_pandas(df_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/matteo/github/social_bias_framework/test_models.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m dataset_val \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mfrom_pandas(df_val)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/matteo/github/social_bias_framework/test_models.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m train_tokenized \u001b[39m=\u001b[39m dataset_train\u001b[39m.\u001b[39mmap(tokenize_function, batched\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/matteo/github/social_bias_framework/test_models.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m val_tokenized \u001b[39m=\u001b[39m df_val\u001b[39m.\u001b[39mmap(tokenize_function, batched\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matteo/github/social_bias_framework/test_models.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m train_tokenized \u001b[39m=\u001b[39m train_tokenized\u001b[39m.\u001b[39mshuffle(seed\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\u001b[39m.\u001b[39mselect(\u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenize_function' is not defined"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "df_train = pd.read_csv(\"data/old_agg/SBIC.v2.agg.trn.csv\")\n",
    "df_val = pd.read_csv(\"data/old_agg/SBIC.v2.agg.dev.csv\")\n",
    "\n",
    "dataset_train = Dataset.from_pandas(df_train)\n",
    "dataset_val = Dataset.from_pandas(df_val)\n",
    "train_tokenized = dataset_train.map(tokenize_function, batched=True)\n",
    "val_tokenized = df_val.map(tokenize_function, batched=True)\n",
    "\n",
    "\n",
    "train_tokenized = train_tokenized.shuffle(seed=42).select(range(1000))\n",
    "val_tokenized = val_tokenized.shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "accelerator = Accelerator(mixed_precision=config.mixed_precision, cpu=config.cpu)\n",
    "(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    lr_scheduler,\n",
    ") = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, val_dataloader, lr_scheduler\n",
    ")\n",
    "if isinstance(loss_fn, nn.Module):\n",
    "    loss_fn = accelerator.prepare(loss_fn)\n",
    "\n",
    "# Run training and track with wandb\n",
    "steps_per_epoch = len(train_dataloader)\n",
    "total_steps = steps_per_epoch * config.num_epochs\n",
    "\n",
    "checkpoint_counter = 0\n",
    "step = 0\n",
    "avg_loss = AvgValue()\n",
    "avg_inner_losses = defaultdict(AvgValue)\n",
    "model.train()\n",
    "\n",
    "forward_signature = set(inspect.signature(model.forward).parameters)\n",
    "progress_bar = tqdm(range(total_steps))\n",
    "for epoch in range(config.num_epochs):\n",
    "    for data in train_dataloader:\n",
    "        inputs = {\n",
    "            argument: value\n",
    "            for argument, value in data.items()\n",
    "            if argument in forward_signature\n",
    "        }\n",
    "\n",
    "        loss, inner_losses = train_batch(\n",
    "            inputs=inputs,\n",
    "            data=data,\n",
    "            step=step,\n",
    "            model=model,\n",
    "            loss_fn=loss_fn,\n",
    "            optimizer=optimizer,\n",
    "            lr_scheduler=lr_scheduler,\n",
    "            teacher_force_scheduler=teacher_force_scheduler,\n",
    "            accelerator=accelerator,\n",
    "            config=config,\n",
    "        )\n",
    "        progress_bar.update(1)\n",
    "\n",
    "        # Compute statistics\n",
    "        n_samples = len(next(iter(data.values())))\n",
    "        step += 1\n",
    "        avg_loss.update(loss, n_samples)\n",
    "        for loss_name, loss_value in inner_losses.items():\n",
    "            avg_inner_losses[f\"avg_{loss_name}\"].update(loss_value, n_samples)\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"train_loss\": loss,\n",
    "                **inner_losses,\n",
    "                \"lr\": lr_scheduler.get_last_lr()[0],\n",
    "            },\n",
    "            step=step,\n",
    "        )\n",
    "\n",
    "        # Evaluate the model and save checkpoints\n",
    "        if (step % config.log_interval == 0) or (step == total_steps):\n",
    "            # Evaluate the model\n",
    "            val_loss, val_inner_losses, val_metrics = train_evaluation(\n",
    "                model,\n",
    "                val_dataloader,\n",
    "                loss_fn,\n",
    "                # metrics=metrics,\n",
    "            )\n",
    "            model.train()\n",
    "\n",
    "            train_log(\n",
    "                avg_loss,\n",
    "                avg_inner_losses,\n",
    "                val_loss,\n",
    "                val_inner_losses,\n",
    "                val_metrics,\n",
    "                lr=lr_scheduler.get_last_lr()[0],\n",
    "                step=step,\n",
    "            )\n",
    "            avg_loss = AvgValue()\n",
    "            avg_inner_losses = defaultdict(AvgValue)\n",
    "\n",
    "        if step % config.checkpoint_interval == 0:\n",
    "            # Saving checkpoint\n",
    "            save_model_checkpoint(\n",
    "                model,\n",
    "                optimizer,\n",
    "                lr_scheduler,\n",
    "                epoch,\n",
    "                step,\n",
    "                checkpoint_counter,\n",
    "                config,\n",
    "            )\n",
    "            wandb.log(\n",
    "                {\n",
    "                    \"checkpoint_counter\": checkpoint_counter,\n",
    "                },\n",
    "                step=step,\n",
    "            )\n",
    "            checkpoint_counter += 1\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
