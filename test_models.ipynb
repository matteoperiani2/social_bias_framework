{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import set_seed\n",
    "\n",
    "from src.config import Config\n",
    "from src.dataset import SBICDataset, SBICDatasetInference\n",
    "from src.utils import PropertyDict\n",
    "from src.train_utils import *\n",
    "\n",
    "CONFIG:Config = Config()\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PropertyDict(\n",
    "    seed=42,\n",
    "    checkpoint_name=\"distilgpt2\",\n",
    "    model_name=\"distilgpt2\",\n",
    "    padding_side=\"left\",\n",
    "    batch_size=32,\n",
    "    val_batch_size=16,\n",
    "    num_workers=0,\n",
    "    num_epochs=20,\n",
    "    learning_rate=5e-4,\n",
    "    scheduler=\"linear\",\n",
    "    warmup_fraction=0.1,\n",
    "    accumulation_steps=1,\n",
    "    gradient_clip = 1.0,\n",
    "    mixed_precision=\"fp16\",\n",
    "    checkpoint_interval=1000,\n",
    "    log_interval=1000,\n",
    "    cpu=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/matteo/github/social_bias_framework/wandb/run-20231002_183007-eqh3zx0q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/matteo-periani/matteo-periani/runs/eqh3zx0q' target=\"_blank\">dutiful-shape-13</a></strong> to <a href='https://wandb.ai/matteo-periani/matteo-periani' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/matteo-periani/matteo-periani' target=\"_blank\">https://wandb.ai/matteo-periani/matteo-periani</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/matteo-periani/matteo-periani/runs/eqh3zx0q' target=\"_blank\">https://wandb.ai/matteo-periani/matteo-periani/runs/eqh3zx0q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all special token and its token_id:\n",
      " - ['<|endoftext|>', '<|sep|>', '<|pad|>', '<|offY|>', '<|offN|>', '<|sexY|>', '<|sexN|>', '<|intY|>', '<|intN|>', '<|grpY|>', '<|grpN|>', '<|ingrpN|>', '<|ingrpY|>']\n",
      " - [[50256], [50258], [50257], [50259], [50260], [50261], [50262], [50263], [50264], [50265], [50266], [50267], [50268]]\n",
      "Model vocab resize: 50269\n",
      "Model eos token: 50256\n",
      "Model pad token: 50257\n",
      "Model sep token: 50258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/640 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 640/640 [02:55<00:00,  3.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>▁▃▅▆███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>1e-05</td></tr><tr><td>train_loss</td><td>0.09683</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dutiful-shape-13</strong> at: <a href='https://wandb.ai/matteo-periani/matteo-periani/runs/eqh3zx0q' target=\"_blank\">https://wandb.ai/matteo-periani/matteo-periani/runs/eqh3zx0q</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231002_183007-eqh3zx0q/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project=CONFIG.wandbConfig.project, config=config):\n",
    "    config = wandb.config\n",
    "\n",
    "    set_seed(CONFIG.seed)\n",
    "\n",
    "    # Make the model\n",
    "    tokenizer = make_tokinzer(config)\n",
    "    model = make_model(config, tokenizer)\n",
    "\n",
    "    # Make the data\n",
    "    train_data = get_data(\"train\")[:1024]\n",
    "    train_dataset = SBICDataset(train_data, tokenizer)\n",
    "\n",
    "    val_data = get_data(\"validation\")[:1024]\n",
    "    val_dataset = SBICDataset(train_data, tokenizer)\n",
    "\n",
    "    train_dataloader = make_dataloader(train_dataset, model, tokenizer, config, split=\"train\")\n",
    "    val_dataloader = make_dataloader(val_dataset, model, tokenizer, config, split=\"validation\")\n",
    "\n",
    "    # Make the loss, the optimizer and the scheduler\n",
    "    optimizer = make_optimizer(model, config)\n",
    "    scheduler = make_scheduler(\n",
    "        optimizer, steps_per_epoch=len(train_dataloader), config=config\n",
    "    )\n",
    "\n",
    "    # model, train_dataloader, val_dataloader, loss_fn, optimizer, scheduler, metrics = make(config)\n",
    "    # print(model)\n",
    "\n",
    "    train(\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        val_dataloader,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        config,\n",
    "    )\n",
    "\n",
    "    # results = evaluate(model, tokenizer, train_data, val_data, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all special token and its token_id:\n",
      " - ['<|endoftext|>', '<|sep|>', '<|pad|>', '<|offY|>', '<|offN|>', '<|sexY|>', '<|sexN|>', '<|intY|>', '<|intN|>', '<|grpY|>', '<|grpN|>', '<|ingrpN|>', '<|ingrpY|>']\n",
      " - [[50256], [50258], [50257], [50259], [50260], [50261], [50262], [50263], [50264], [50265], [50266], [50267], [50268]]\n",
      "Model vocab resize: 50269\n",
      "Model eos token: 50256\n",
      "Model pad token: 50257\n",
      "Model sep token: 50258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = make_tokinzer(config)\n",
    "model = make_model(config, tokenizer)\n",
    "model.load_state_dict(torch.load(\"checkpoints/distilgpt2_1024_32.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to(CONFIG.train_params.device)\n",
    "\n",
    "n_samples = 1024\n",
    "split = \"train\"\n",
    "# split = \"validation\"\n",
    "\n",
    "data = get_data(split)[:n_samples]\n",
    "dataset = SBICDataset(data, tokenizer, is_training=False)\n",
    "dataloader = make_dataloader(dataset, model, tokenizer, config, split=split)\n",
    "\n",
    "val_f1 = []\n",
    "with torch.no_grad():\n",
    "    for n_iers, bacth in enumerate(tqdm(dataloader, leave=False, total=len(val_dataloader))):\n",
    "        labels = bacth[\"labels\"].numpy().astype(int)\n",
    "\n",
    "        generate_out = model.generate(inputs = bacth[\"input_ids\"].to(CONFIG.train_params.device),\n",
    "                                      max_new_tokens=50)\n",
    "        generate_tokens = generate_out.cpu().numpy()\n",
    "        \n",
    "        class_tokens = [gen[np.where(gen == tokenizer.sep_token_id)[0][0]+1:np.where(gen == tokenizer.sep_token_id)[0][0]+5] for gen in generate_tokens] # select only 4 class tokens after 1st sep\n",
    "        class_labels =[l[np.where(l == tokenizer.sep_token_id)[0][0]+1:np.where(l == tokenizer.sep_token_id)[0][1]] for l in labels] # select only 4 labels tokens after 1st sep\n",
    "\n",
    "        batch_f1 = []\n",
    "        for labels, gen_tokens in zip(class_labels, class_tokens):\n",
    "            batch_f1.append(f1_score(labels, gen_tokens, average=\"macro\"))\n",
    "        \n",
    "        val_f1.append(np.mean(batch_f1))\n",
    "\n",
    "print(f\"Validation F1-Score on classification task: {np.mean(val_f1)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
